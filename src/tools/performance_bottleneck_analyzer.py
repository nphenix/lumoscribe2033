"""
æ€§èƒ½ç“¶é¢ˆåˆ†æå·¥å…·

ç”¨äºè¯†åˆ«å’Œåˆ†æç³»ç»Ÿä¸­çš„æ€§èƒ½ç“¶é¢ˆï¼Œæä¾›å…·ä½“çš„ä¼˜åŒ–å»ºè®®
"""

import asyncio
import time
from collections import defaultdict
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

import psutil

from src.framework.shared.logging import get_logger
from src.framework.shared.monitoring import get_metrics_collector
from src.framework.shared.performance import (
    get_performance_optimizer,
    get_redis_optimizer,
    get_chroma_optimizer,
    get_sqlite_optimizer,
    get_networkx_optimizer
)

logger = get_logger(__name__)


@dataclass
class BottleneckReport:
    """æ€§èƒ½ç“¶é¢ˆæŠ¥å‘Š"""
    timestamp: str
    component: str
    severity: str  # critical, high, medium, low
    issue: str
    impact: str
    recommendation: str
    metrics: Dict[str, Any]
    estimated_gain: str  # é¢„ä¼°æ€§èƒ½æå‡


class PerformanceBottleneckAnalyzer:
    """æ€§èƒ½ç“¶é¢ˆåˆ†æå™¨"""

    def __init__(self):
        self.metrics_collector = get_metrics_collector()
        self.performance_optimizer = get_performance_optimizer()
        
        # åˆå§‹åŒ–å„ä¸ªä¼˜åŒ–å™¨
        self.redis_optimizer = get_redis_optimizer()
        self.chroma_optimizer = get_chroma_optimizer()
        self.sqlite_optimizer = get_sqlite_optimizer()
        self.networkx_optimizer = get_networkx_optimizer()
        
        # åˆ†æç»“æœç¼“å­˜
        self.analysis_cache = {}
        self.last_analysis_time = None
        
        logger.info("ğŸ” æ€§èƒ½ç“¶é¢ˆåˆ†æå™¨å·²åˆå§‹åŒ–")

    async def comprehensive_analysis(self) -> Dict[str, Any]:
        """æ‰§è¡Œå…¨é¢çš„æ€§èƒ½ç“¶é¢ˆåˆ†æ"""
        start_time = time.time()
        logger.info("ğŸ” å¼€å§‹å…¨é¢æ€§èƒ½ç“¶é¢ˆåˆ†æ...")
        
        analysis_results = {
            "timestamp": datetime.now().isoformat(),
            "analysis_duration": 0,
            "system_resources": await self._analyze_system_resources(),
            "database_performance": await self._analyze_database_performance(),
            "cache_performance": await self._analyze_cache_performance(),
            "vector_search_performance": await self._analyze_vector_search_performance(),
            "graph_computation_performance": await self._analyze_graph_computation_performance(),
            "api_performance": await self._analyze_api_performance(),
            "bottlenecks": [],
            "recommendations": [],
            "performance_score": 0
        }
        
        # æ”¶é›†æ‰€æœ‰ç“¶é¢ˆ
        all_bottlenecks = []
        for category, data in analysis_results.items():
            if isinstance(data, dict) and "bottlenecks" in data:
                all_bottlenecks.extend(data["bottlenecks"])
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åº
        all_bottlenecks.sort(key=lambda x: self._severity_score(x.severity), reverse=True)
        analysis_results["bottlenecks"] = all_bottlenecks[:10]  # å–å‰10ä¸ªæœ€ä¸¥é‡çš„ç“¶é¢ˆ
        
        # ç”Ÿæˆç»¼åˆå»ºè®®
        analysis_results["recommendations"] = self._generate_comprehensive_recommendations(all_bottlenecks)
        
        # è®¡ç®—æ€§èƒ½è¯„åˆ†
        analysis_results["performance_score"] = self._calculate_performance_score(all_bottlenecks)
        
        analysis_results["analysis_duration"] = time.time() - start_time
        self.last_analysis_time = datetime.now()
        
        logger.info(f"âœ… æ€§èƒ½ç“¶é¢ˆåˆ†æå®Œæˆï¼Œè€—æ—¶: {analysis_results['analysis_duration']:.2f}s")
        return analysis_results

    async def _analyze_system_resources(self) -> Dict[str, Any]:
        """åˆ†æç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        bottlenecks = []
        recommendations = []
        
        try:
            # CPUä½¿ç”¨ç‡åˆ†æ
            cpu_percent = psutil.cpu_percent(interval=1)
            if cpu_percent > 80:
                bottlenecks.append(BottleneckReport(
                    timestamp=datetime.now().isoformat(),
                    component="system",
                    severity="critical" if cpu_percent > 90 else "high",
                    issue=f"CPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_percent:.1f}%",
                    impact="ç³»ç»Ÿå“åº”å˜æ…¢ï¼Œå¯èƒ½å½±å“æ‰€æœ‰æ“ä½œ",
                    recommendation="ä¼˜åŒ–CPUå¯†é›†å‹æ“ä½œï¼Œè€ƒè™‘å¢åŠ å¤„ç†èƒ½åŠ›æˆ–è´Ÿè½½å‡è¡¡",
                    metrics={"cpu_percent": cpu_percent},
                    estimated_gain="20-40%æ€§èƒ½æå‡"
                ))
            
            # å†…å­˜ä½¿ç”¨ç‡åˆ†æ
            memory = psutil.virtual_memory()
            if memory.percent > 80:
                bottlenecks.append(BottleneckReport(
                    timestamp=datetime.now().isoformat(),
                    component="system",
                    severity="critical" if memory.percent > 90 else "high",
                    issue=f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory.percent:.1f}%",
                    impact="å¯èƒ½å¯¼è‡´å†…å­˜ä¸è¶³é”™è¯¯å’Œç³»ç»Ÿä¸ç¨³å®š",
                    recommendation="ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œå¢åŠ å†…å­˜å®¹é‡æˆ–å®æ–½å†…å­˜ç¼“å­˜ç­–ç•¥",
                    metrics={"memory_percent": memory.percent, "used_gb": memory.used / (1024**3)},
                    estimated_gain="15-30%ç¨³å®šæ€§æå‡"
                ))
            
            # ç£ç›˜I/Oåˆ†æ
            disk_io = psutil.disk_io_counters()
            if disk_io:
                # ç®€å•çš„ç£ç›˜ä½¿ç”¨ç‡æ£€æŸ¥
                disk_usage = psutil.disk_usage('/')
                if disk_usage.percent > 85:
                    bottlenecks.append(BottleneckReport(
                        timestamp=datetime.now().isoformat(),
                        component="system",
                        severity="high",
                        issue=f"ç£ç›˜ç©ºé—´ä¸è¶³: {disk_usage.percent:.1f}%",
                        impact="å¯èƒ½å½±å“æ—¥å¿—å†™å…¥å’Œæ•°æ®å­˜å‚¨",
                        recommendation="æ¸…ç†ä¸å¿…è¦çš„æ–‡ä»¶ï¼Œæ‰©å±•å­˜å‚¨ç©ºé—´",
                        metrics={"disk_percent": disk_usage.percent, "free_gb": disk_usage.free / (1024**3)},
                        estimated_gain="é¿å…æœåŠ¡ä¸­æ–­"
                    ))
            
            # ç½‘ç»œI/Oåˆ†æ
            network_io = psutil.net_io_counters()
            if network_io:
                # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„ç½‘ç»œåˆ†æé€»è¾‘
                pass
            
            if not bottlenecks:
                recommendations.append("ç³»ç»Ÿèµ„æºä½¿ç”¨æ­£å¸¸ï¼Œç»§ç»­ä¿æŒå½“å‰é…ç½®")
            
        except Exception as e:
            logger.error(f"ç³»ç»Ÿèµ„æºåˆ†æå¤±è´¥: {e}")
            bottlenecks.append(BottleneckReport(
                timestamp=datetime.now().isoformat(),
                component="system",
                severity="medium",
                issue="ç³»ç»Ÿèµ„æºç›‘æ§å¼‚å¸¸",
                impact="æ— æ³•å‡†ç¡®è¯„ä¼°ç³»ç»Ÿæ€§èƒ½",
                recommendation="æ£€æŸ¥ç³»ç»Ÿç›‘æ§å·¥å…·é…ç½®",
                metrics={"error": str(e)},
                estimated_gain="æå‡ç›‘æ§å¯é æ€§"
            ))
        
        return {
            "component": "system_resources",
            "status": "healthy" if not bottlenecks else "degraded",
            "bottlenecks": bottlenecks,
            "recommendations": recommendations,
            "metrics": {
                "cpu_percent": cpu_percent,
                "memory_percent": memory.percent,
                "disk_percent": disk_usage.percent if 'disk_usage' in locals() else 0
            }
        }

    async def _analyze_database_performance(self) -> Dict[str, Any]:
        """åˆ†ææ•°æ®åº“æ€§èƒ½"""
        bottlenecks = []
        recommendations = []
        
        try:
            # è·å–SQLiteæ€§èƒ½ç»Ÿè®¡
            sqlite_stats = self.sqlite_optimizer.get_sqlite_performance_stats()
            
            # æ£€æŸ¥æŸ¥è¯¢ç¼“å­˜å¤§å°
            cache_size = sqlite_stats.get("query_cache_size", 0)
            if cache_size > 1000:
                bottlenecks.append(BottleneckReport(
                    timestamp=datetime.now().isoformat(),
                    component="database",
                    severity="medium",
                    issue=f"æŸ¥è¯¢ç¼“å­˜è¿‡å¤§: {cache_size}é¡¹",
                    impact="å ç”¨è¿‡å¤šå†…å­˜ï¼Œå¯èƒ½å½±å“æ€§èƒ½",
                    recommendation="å®šæœŸæ¸…ç†æŸ¥è¯¢ç¼“å­˜ï¼Œå®æ–½LRUç­–ç•¥",
                    metrics=sqlite_stats,
                    estimated_gain="5-15%å†…å­˜ä¼˜åŒ–"
                ))
            
            # æ£€æŸ¥ç´¢å¼•ä¼˜åŒ–æƒ…å†µ
            index_stats = sqlite_stats.get("index_stats", {})
            if not index_stats:
                bottlenecks.append(BottleneckReport(
                    timestamp=datetime.now().isoformat(),
                    component="database",
                    severity="high",
                    issue="ç¼ºå°‘æ•°æ®åº“ç´¢å¼•",
                    impact="æŸ¥è¯¢æ€§èƒ½ä½ä¸‹ï¼Œç‰¹åˆ«æ˜¯å¤æ‚æŸ¥è¯¢",
                    recommendation="ä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µåˆ›å»ºç´¢å¼•",
                    metrics=sqlite_stats,
                    estimated_gain="30-70%æŸ¥è¯¢æ€§èƒ½æå‡"
                ))
            
            # è·å–æ€§èƒ½ä¼˜åŒ–å™¨çš„æ…¢æŸ¥è¯¢
            slow_queries = self.performance_optimizer.get_slow_queries(threshold=2.0)
            if slow_queries:
                bottlenecks.append(BottleneckReport(
                    timestamp=datetime.now().isoformat(),
                    component="database",
                    severity="high",
                    issue=f"å‘ç°{len(slow_queries)}ä¸ªæ…¢æŸ¥è¯¢",
                    impact="æ•°æ®åº“å“åº”æ—¶é—´è¿‡é•¿ï¼Œå½±å“æ•´ä½“æ€§èƒ½",
                    recommendation="ä¼˜åŒ–æ…¢æŸ¥è¯¢ï¼Œæ·»åŠ ç´¢å¼•ï¼Œè€ƒè™‘æŸ¥è¯¢é‡å†™",
                    metrics={"slow_query_count": len(slow_queries), "queries": slow_queries[:5]},
                    estimated_gain="20-50%æŸ¥è¯¢æ€§èƒ½æå‡"
                ))
            
            # ç”Ÿæˆå»ºè®®
            sqlite_recommendations = sqlite_stats.get("recommendations", [])
            recommendations.extend(sqlite_recommendations)
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“æ€§èƒ½åˆ†æå¤±è´¥: {e}")
            bottlenecks.append(BottleneckReport(
                timestamp=datetime.now().isoformat(),
                component="database",
                severity="medium",
                issue="æ•°æ®åº“æ€§èƒ½åˆ†æå¼‚å¸¸",
                impact="æ— æ³•å‡†ç¡®è¯„ä¼°æ•°æ®åº“æ€§èƒ½",
                recommendation="æ£€æŸ¥æ•°æ®åº“è¿æ¥å’Œé…ç½®",
                metrics={"error": str(e)},
                estimated_gain="æå‡æ•°æ®åº“ç›‘æ§èƒ½åŠ›"
            ))
        
        return {
            "component": "database_performance",
            "status": "healthy" if not bottlenecks else "degraded",
            "bottlenecks": bottlenecks,
            "recommendations": recommendations,
            "metrics": sqlite_stats if 'sqlite_stats' in locals() else {}
        }

    async def _analyze_cache_performance(self) -> Dict[str, Any]:
        """åˆ†æç¼“å­˜æ€§èƒ½"""
        bottlenecks = []
        recommendations = []
        
        try:
            # è·å–Redisæ€§èƒ½ç»Ÿè®¡
            redis_stats = self.redis_optimizer.get_redis_performance_stats()
            
            # æ£€æŸ¥è¿æ¥æ± ç»Ÿè®¡
            pool_stats = redis_stats.get("connection_pool_stats", {})
            pool_hits = pool_stats.get("pool_hits", 0)
            pool_misses = pool_stats.get("pool_misses", 0)
            
            if pool_misses > pool_hits:
                bottlenecks.append(BottleneckReport(
                    timestamp=datetime.now().isoformat(),
                    component="cache",
                    severity="high",
                    issue="Redisè¿æ¥æ± å‘½ä¸­ç‡ä½",
                    impact="é¢‘ç¹åˆ›å»ºè¿æ¥ï¼Œå¢åŠ å»¶è¿Ÿ",
                    recommendation="ä¼˜åŒ–è¿æ¥æ± é…ç½®ï¼Œå¢åŠ è¿æ¥æ± å¤§å°",
                    metrics=pool_stats,
                    estimated_gain="10-25%ç¼“å­˜æ€§èƒ½æå‡"
                ))
            
            # è·å–æ€§èƒ½ä¼˜åŒ–å™¨çš„ç¼“å­˜ç»Ÿè®¡
            perf_stats = self.performance_optimizer.get_performance_stats()
            cache_stats = perf_stats.get("cache_stats", {})
            cache_hit_rate = cache_stats.get("cache_hit_rate", 0)
            
            if cache_hit_rate < 50:
                bottlenecks.append(BottleneckReport(
                    timestamp=datetime.now().isoformat(),
                    component="cache",
                    severity="high",
                    issue=f"ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½: {cache_hit_rate:.1f}%",
                    impact="å¢åŠ åç«¯è´Ÿè½½ï¼Œé™ä½å“åº”é€Ÿåº¦",
                    recommendation="ä¼˜åŒ–ç¼“å­˜ç­–ç•¥ï¼Œå¢åŠ ç¼“å­˜é¢„çƒ­ï¼Œè°ƒæ•´TTL",
                    metrics=cache_stats,
                    estimated_gain="20-40%å“åº”é€Ÿåº¦æå‡"
                ))
            
            # ç”Ÿæˆå»ºè®®
            redis_recommendations = redis_stats.get("recommendations", [])
            recommendations.extend(redis_recommendations)
            
        except Exception as e:
            logger.error(f"ç¼“å­˜æ€§èƒ½åˆ†æå¤±è´¥: {e}")
            bottlenecks.append(BottleneckReport(
                timestamp=datetime.now().isoformat(),
                component="cache",
                severity="medium",
                issue="ç¼“å­˜æ€§èƒ½åˆ†æå¼‚å¸¸",
                impact="æ— æ³•å‡†ç¡®è¯„ä¼°ç¼“å­˜æ€§èƒ½",
                recommendation="æ£€æŸ¥Redisè¿æ¥å’Œé…ç½®",
                metrics={"error": str(e)},
                estimated_gain="æå‡ç¼“å­˜ç›‘æ§èƒ½åŠ›"
            ))
        
        return {
            "component": "cache_performance",
            "status": "healthy" if not bottlenecks else "degraded",
            "bottlenecks": bottlenecks,
            "recommendations": recommendations,
            "metrics": redis_stats if 'redis_stats' in locals() else {}
        }

    async def _analyze_vector_search_performance(self) -> Dict[str, Any]:
        """åˆ†æå‘é‡æœç´¢æ€§èƒ½"""
        bottlenecks = []
        recommendations = []
        
        try:
            # è·å–ChromaDBæ€§èƒ½ç»Ÿè®¡
            chroma_stats = self.chroma_optimizer.get_chroma_performance_stats()
            
            # æ£€æŸ¥æ‰¹é‡æŸ¥è¯¢æ¯”ä¾‹
            perf_metrics = chroma_stats.get("performance_metrics", {})
            batch_ratio = perf_metrics.get("batch_query_ratio", 0)
            
            if batch_ratio < 0.7:
                bottlenecks.append(BottleneckReport(
                    timestamp=datetime.now().isoformat(),
                    component="vector_search",
                    severity="medium",
                    issue=f"æ‰¹é‡æŸ¥è¯¢æ¯”ä¾‹è¿‡ä½: {batch_ratio:.1%}",
                    impact="å¢åŠ ç½‘ç»œå¼€é”€ï¼Œé™ä½æ•´ä½“ååé‡",
                    recommendation="å°½å¯èƒ½ä½¿ç”¨æ‰¹é‡æŸ¥è¯¢APIï¼Œåˆå¹¶å•ç‹¬æŸ¥è¯¢",
                    metrics=perf_metrics,
                    estimated_gain="15-35%æœç´¢æ€§èƒ½æå‡"
                ))
            
            # æ£€æŸ¥å¹³å‡æŸ¥è¯¢æ—¶é—´
            avg_query_time = perf_metrics.get("avg_query_time", 0)
            if avg_query_time > 1.0:
                bottlenecks.append(BottleneckReport(
                    timestamp=datetime.now().isoformat(),
                    component="vector_search",
                    severity="high",
                    issue=f"å¹³å‡æŸ¥è¯¢æ—¶é—´è¿‡é•¿: {avg_query_time:.3f}s",
                    impact="ç”¨æˆ·ç­‰å¾…æ—¶é—´å¢åŠ ï¼Œå½±å“ä½“éªŒ",
                    recommendation="ä¼˜åŒ–HNSWå‚æ•°ï¼Œå‡å°‘è¿”å›ç»“æœæ•°é‡ï¼Œä¼˜åŒ–æŸ¥è¯¢å‘é‡",
                    metrics=perf_metrics,
                    estimated_gain="25-50%æŸ¥è¯¢é€Ÿåº¦æå‡"
                ))
            
            # ç”Ÿæˆå»ºè®®
            chroma_recommendations = chroma_stats.get("recommendations", [])
            recommendations.extend(chroma_recommendations)
            
        except Exception as e:
            logger.error(f"å‘é‡æœç´¢æ€§èƒ½åˆ†æå¤±è´¥: {e}")
            bottlenecks.append(BottleneckReport(
                timestamp=datetime.now().isoformat(),
                component="vector_search",
                severity="medium",
                issue="å‘é‡æœç´¢æ€§èƒ½åˆ†æå¼‚å¸¸",
                impact="æ— æ³•å‡†ç¡®è¯„ä¼°æœç´¢æ€§èƒ½",
                recommendation="æ£€æŸ¥ChromaDBè¿æ¥å’Œé…ç½®",
                metrics={"error": str(e)},
                estimated_gain="æå‡æœç´¢ç›‘æ§èƒ½åŠ›"
            ))
        
        return {
            "component": "vector_search_performance",
            "status": "healthy" if not bottlenecks else "degraded",
            "bottlenecks": bottlenecks,
            "recommendations": recommendations,
            "metrics": chroma_stats if 'chroma_stats' in locals() else {}
        }

    async def _analyze_graph_computation_performance(self) -> Dict[str, Any]:
        """åˆ†æå›¾è®¡ç®—æ€§èƒ½"""
        bottlenecks = []
        recommendations = []
        
        try:
            # è·å–NetworkXæ€§èƒ½ç»Ÿè®¡
            networkx_stats = self.networkx_optimizer.get_networkx_performance_stats()
            
            # æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
            cache_hit_rate = networkx_stats.get("cache_hit_rate", 0)
            if cache_hit_rate < 0.5:
                bottlenecks.append(BottleneckReport(
                    timestamp=datetime.now().isoformat(),
                    component="graph_computation",
                    severity="medium",
                    issue=f"å›¾è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½: {cache_hit_rate:.1%}",
                    impact="é‡å¤è®¡ç®—å¢åŠ CPUè´Ÿè½½",
                    recommendation="å¢åŠ ç¼“å­˜å®¹é‡ï¼Œä¼˜åŒ–ç¼“å­˜é”®ç”Ÿæˆç­–ç•¥",
                    metrics=networkx_stats,
                    estimated_gain="20-40%è®¡ç®—æ€§èƒ½æå‡"
                ))
            
            # æ£€æŸ¥å¹³å‡è®¡ç®—æ—¶é—´
            comp_stats = networkx_stats.get("computation_stats", {})
            avg_time = comp_stats.get("avg_computation_time", 0)
            if avg_time >= 1.0:
                bottlenecks.append(BottleneckReport(
                    timestamp=datetime.now().isoformat(),
                    component="graph_computation",
                    severity="high",
                    issue=f"å¹³å‡å›¾è®¡ç®—æ—¶é—´è¿‡é•¿: {avg_time:.3f}s",
                    impact="å½±å“ä¾èµ–å›¾è®¡ç®—çš„åŠŸèƒ½æ€§èƒ½",
                    recommendation="ä½¿ç”¨æ›´é«˜æ•ˆçš„ç®—æ³•ï¼Œè€ƒè™‘å›¾åˆ†å‰²å¤„ç†ï¼Œä½¿ç”¨å¹¶è¡Œè®¡ç®—",
                    metrics=comp_stats,
                    estimated_gain="30-60%è®¡ç®—é€Ÿåº¦æå‡"
                ))
            
            # ç”Ÿæˆå»ºè®®
            networkx_recommendations = networkx_stats.get("recommendations", [])
            recommendations.extend(networkx_recommendations)
            
        except Exception as e:
            logger.error(f"å›¾è®¡ç®—æ€§èƒ½åˆ†æå¤±è´¥: {e}")
            bottlenecks.append(BottleneckReport(
                timestamp=datetime.now().isoformat(),
                component="graph_computation",
                severity="medium",
                issue="å›¾è®¡ç®—æ€§èƒ½åˆ†æå¼‚å¸¸",
                impact="æ— æ³•å‡†ç¡®è¯„ä¼°å›¾è®¡ç®—æ€§èƒ½",
                recommendation="æ£€æŸ¥NetworkXé…ç½®å’Œå›¾æ•°æ®ç»“æ„",
                metrics={"error": str(e)},
                estimated_gain="æå‡å›¾è®¡ç®—ç›‘æ§èƒ½åŠ›"
            ))
        
        return {
            "component": "graph_computation_performance",
            "status": "healthy" if not bottlenecks else "degraded",
            "bottlenecks": bottlenecks,
            "recommendations": recommendations,
            "metrics": networkx_stats if 'networkx_stats' in locals() else {}
        }

    async def _analyze_api_performance(self) -> Dict[str, Any]:
        """åˆ†æAPIæ€§èƒ½"""
        bottlenecks = []
        recommendations = []
        
        try:
            # è·å–APIæŒ‡æ ‡æ‘˜è¦
            api_summary = self.metrics_collector.get_api_summary(hours=1)
            
            if not api_summary:
                recommendations.append("æš‚æ— è¶³å¤Ÿçš„APIæ€§èƒ½æ•°æ®ï¼Œå»ºè®®æ”¶é›†æ›´å¤šæ•°æ®åé‡æ–°åˆ†æ")
                return {
                    "component": "api_performance",
                    "status": "unknown",
                    "bottlenecks": bottlenecks,
                    "recommendations": recommendations,
                    "metrics": {}
                }
            
            # åˆ†æå„ç«¯ç‚¹çš„æ€§èƒ½
            for endpoint, stats in api_summary.items():
                avg_response_time = stats.get("avg_response_time", 0)
                success_rate = stats.get("success_rate", 100)
                total_requests = stats.get("total_requests", 0)
                
                # æ£€æŸ¥å“åº”æ—¶é—´
                if avg_response_time > 3.0:
                    bottlenecks.append(BottleneckReport(
                        timestamp=datetime.now().isoformat(),
                        component="api",
                        severity="high",
                        issue=f"ç«¯ç‚¹ {endpoint} å“åº”æ—¶é—´è¿‡é•¿: {avg_response_time:.2f}s",
                        impact="ç”¨æˆ·ä½“éªŒå·®ï¼Œå¯èƒ½å½±å“ç³»ç»Ÿå¯ç”¨æ€§",
                        recommendation="ä¼˜åŒ–ç«¯ç‚¹é€»è¾‘ï¼Œæ·»åŠ ç¼“å­˜ï¼Œå‡å°‘æ•°æ®åº“æŸ¥è¯¢",
                        metrics={"endpoint": endpoint, "avg_response_time": avg_response_time},
                        estimated_gain="30-50%å“åº”é€Ÿåº¦æå‡"
                    ))
                elif avg_response_time > 1.5:
                    bottlenecks.append(BottleneckReport(
                        timestamp=datetime.now().isoformat(),
                        component="api",
                        severity="medium",
                        issue=f"ç«¯ç‚¹ {endpoint} å“åº”æ—¶é—´è¾ƒé•¿: {avg_response_time:.2f}s",
                        impact="ç”¨æˆ·ä½“éªŒä¸€èˆ¬ï¼Œæœ‰ä¼˜åŒ–ç©ºé—´",
                        recommendation="åˆ†æç«¯ç‚¹æ€§èƒ½ç“¶é¢ˆï¼Œè€ƒè™‘å¼‚æ­¥å¤„ç†",
                        metrics={"endpoint": endpoint, "avg_response_time": avg_response_time},
                        estimated_gain="15-25%å“åº”é€Ÿåº¦æå‡"
                    ))
                
                # æ£€æŸ¥æˆåŠŸç‡
                if success_rate < 95:
                    bottlenecks.append(BottleneckReport(
                        timestamp=datetime.now().isoformat(),
                        component="api",
                        severity="high",
                        issue=f"ç«¯ç‚¹ {endpoint} æˆåŠŸç‡è¿‡ä½: {success_rate:.1f}%",
                        impact="æœåŠ¡ä¸ç¨³å®šï¼Œå½±å“ç”¨æˆ·ä¿¡ä»»åº¦",
                        recommendation="å¢å¼ºé”™è¯¯å¤„ç†ï¼Œæ”¹è¿›è¾“å…¥éªŒè¯ï¼Œæé«˜ç³»ç»Ÿç¨³å®šæ€§",
                        metrics={"endpoint": endpoint, "success_rate": success_rate},
                        estimated_gain="æå‡æœåŠ¡å¯é æ€§"
                    ))
            
            # ç”Ÿæˆç»¼åˆå»ºè®®
            if not bottlenecks:
                recommendations.append("APIæ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œç»§ç»­ä¿æŒå½“å‰ä¼˜åŒ–æ°´å¹³")
            else:
                recommendations.extend([
                    "å®æ–½APIæ€§èƒ½ç›‘æ§å’Œå‘Šè­¦",
                    "å®šæœŸè¿›è¡ŒAPIæ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ–",
                    "è€ƒè™‘å®æ–½APIç½‘å…³è¿›è¡Œç»Ÿä¸€ç®¡ç†å’Œä¼˜åŒ–"
                ])
            
        except Exception as e:
            logger.error(f"APIæ€§èƒ½åˆ†æå¤±è´¥: {e}")
            bottlenecks.append(BottleneckReport(
                timestamp=datetime.now().isoformat(),
                component="api",
                severity="medium",
                issue="APIæ€§èƒ½åˆ†æå¼‚å¸¸",
                impact="æ— æ³•å‡†ç¡®è¯„ä¼°APIæ€§èƒ½",
                recommendation="æ£€æŸ¥APIç›‘æ§é…ç½®å’Œæ•°æ®æ”¶é›†",
                metrics={"error": str(e)},
                estimated_gain="æå‡APIç›‘æ§èƒ½åŠ›"
            ))
        
        return {
            "component": "api_performance",
            "status": "healthy" if not bottlenecks else "degraded",
            "bottlenecks": bottlenecks,
            "recommendations": recommendations,
            "metrics": api_summary
        }

    def _severity_score(self, severity: str) -> int:
        """å°†ä¸¥é‡ç¨‹åº¦è½¬æ¢ä¸ºæ•°å€¼åˆ†æ•°"""
        severity_map = {
            "critical": 4,
            "high": 3,
            "medium": 2,
            "low": 1
        }
        return severity_map.get(severity, 0)

    def _generate_comprehensive_recommendations(self, bottlenecks: List[BottleneckReport]) -> List[str]:
        """ç”Ÿæˆç»¼åˆä¼˜åŒ–å»ºè®®"""
        if not bottlenecks:
            return ["ç³»ç»Ÿæ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œç»§ç»­ä¿æŒå½“å‰é…ç½®"]
        
        # æŒ‰ç»„ä»¶åˆ†ç»„ç“¶é¢ˆ
        component_bottlenecks = defaultdict(list)
        for bottleneck in bottlenecks:
            component_bottlenecks[bottleneck.component].append(bottleneck)
        
        recommendations = []
        
        # ä¸ºæ¯ä¸ªç»„ä»¶ç”Ÿæˆå»ºè®®
        for component, component_bottlenecks in component_bottlenecks.items():
            critical_count = len([b for b in component_bottlenecks if b.severity == "critical"])
            high_count = len([b for b in component_bottlenecks if b.severity == "high"])
            
            if critical_count > 0:
                recommendations.append(f"ğŸš¨ {component}ç»„ä»¶å­˜åœ¨{critical_count}ä¸ªä¸¥é‡é—®é¢˜ï¼Œéœ€è¦ç«‹å³å¤„ç†")
            
            if high_count > 0:
                recommendations.append(f"âš ï¸ {component}ç»„ä»¶å­˜åœ¨{high_count}ä¸ªé«˜ä¼˜å…ˆçº§é—®é¢˜ï¼Œå»ºè®®ä¼˜å…ˆè§£å†³")
        
        # é€šç”¨å»ºè®®
        recommendations.extend([
            "ğŸ“Š å»ºç«‹å®Œå–„çš„æ€§èƒ½ç›‘æ§ä½“ç³»ï¼Œå®æ—¶è·Ÿè¸ªå…³é”®æŒ‡æ ‡",
            "ğŸ”§ å®šæœŸè¿›è¡Œæ€§èƒ½è¯„ä¼°å’Œä¼˜åŒ–ï¼Œé¢„é˜²æ€§èƒ½é€€åŒ–",
            "ğŸ“ˆ å®æ–½æ€§èƒ½é¢„ç®—å’Œå‘Šè­¦æœºåˆ¶ï¼Œç¡®ä¿æœåŠ¡è´¨é‡",
            "ğŸš€ è€ƒè™‘å®æ–½è‡ªåŠ¨æ‰©ç¼©å®¹å’Œè´Ÿè½½å‡è¡¡ï¼Œæå‡ç³»ç»Ÿå¼¹æ€§"
        ])
        
        return recommendations

    def _calculate_performance_score(self, bottlenecks: List[BottleneckReport]) -> int:
        """è®¡ç®—æ€§èƒ½è¯„åˆ† (0-100)"""
        if not bottlenecks:
            return 100
        
        # æ ¹æ®ç“¶é¢ˆä¸¥é‡ç¨‹åº¦è®¡ç®—æ‰£åˆ†
        total_deduction = 0
        for bottleneck in bottlenecks:
            if bottleneck.severity == "critical":
                total_deduction += 25
            elif bottleneck.severity == "high":
                total_deduction += 15
            elif bottleneck.severity == "medium":
                total_deduction += 8
            elif bottleneck.severity == "low":
                total_deduction += 3
        
        score = max(0, 100 - total_deduction)
        return score

    async def generate_optimization_plan(self, analysis_results: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºåˆ†æç»“æœç”Ÿæˆä¼˜åŒ–è®¡åˆ’"""
        bottlenecks = analysis_results.get("bottlenecks", [])
        
        # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
        critical_issues = [b for b in bottlenecks if b.severity == "critical"]
        high_issues = [b for b in bottlenecks if b.severity == "high"]
        medium_issues = [b for b in bottlenecks if b.severity == "medium"]
        low_issues = [b for b in bottlenecks if b.severity == "low"]
        
        optimization_plan = {
            "timestamp": datetime.now().isoformat(),
            "performance_score": analysis_results.get("performance_score", 0),
            "phases": [],
            "estimated_total_gain": "å…¨é¢æå‡ç³»ç»Ÿæ€§èƒ½",
            "implementation_priority": []
        }
        
        # ç¬¬ä¸€é˜¶æ®µï¼šå¤„ç†å…³é”®é—®é¢˜
        if critical_issues:
            phase1 = {
                "phase": 1,
                "name": "ç´§æ€¥ä¿®å¤",
                "duration": "1-2å‘¨",
                "focus": "è§£å†³å…³é”®æ€§èƒ½é—®é¢˜",
                "tasks": [
                    {
                        "task": f"ä¿®å¤{issue.component}ç»„ä»¶: {issue.issue}",
                        "priority": "critical",
                        "estimated_gain": issue.estimated_gain,
                        "implementation": issue.recommendation
                    }
                    for issue in critical_issues
                ]
            }
            optimization_plan["phases"].append(phase1)
        
        # ç¬¬äºŒé˜¶æ®µï¼šé«˜ä¼˜å…ˆçº§ä¼˜åŒ–
        if high_issues:
            phase2 = {
                "phase": 2,
                "name": "æ€§èƒ½ä¼˜åŒ–",
                "duration": "2-4å‘¨",
                "focus": "è§£å†³é«˜ä¼˜å…ˆçº§æ€§èƒ½é—®é¢˜",
                "tasks": [
                    {
                        "task": f"ä¼˜åŒ–{issue.component}ç»„ä»¶: {issue.issue}",
                        "priority": "high",
                        "estimated_gain": issue.estimated_gain,
                        "implementation": issue.recommendation
                    }
                    for issue in high_issues
                ]
            }
            optimization_plan["phases"].append(phase2)
        
        # ç¬¬ä¸‰é˜¶æ®µï¼šæŒç»­æ”¹è¿›
        if medium_issues or low_issues:
            remaining_issues = medium_issues + low_issues
            phase3 = {
                "phase": 3,
                "name": "æŒç»­æ”¹è¿›",
                "duration": "4-8å‘¨",
                "focus": "å¤„ç†å‰©ä½™æ€§èƒ½é—®é¢˜",
                "tasks": [
                    {
                        "task": f"æ”¹è¿›{issue.component}ç»„ä»¶: {issue.issue}",
                        "priority": issue.severity,
                        "estimated_gain": issue.estimated_gain,
                        "implementation": issue.recommendation
                    }
                    for issue in remaining_issues
                ]
            }
            optimization_plan["phases"].append(phase3)
        
        # ç”Ÿæˆå®æ–½ä¼˜å…ˆçº§åˆ—è¡¨
        all_tasks = []
        for phase in optimization_plan["phases"]:
            all_tasks.extend(phase["tasks"])
        
        # æŒ‰å½±å“ç¨‹åº¦æ’åº
        all_tasks.sort(key=lambda x: self._priority_score(x["priority"]), reverse=True)
        optimization_plan["implementation_priority"] = all_tasks[:10]  # å–å‰10ä¸ªä»»åŠ¡
        
        return optimization_plan

    def _priority_score(self, priority: str) -> int:
        """å°†ä¼˜å…ˆçº§è½¬æ¢ä¸ºæ•°å€¼åˆ†æ•°"""
        priority_map = {
            "critical": 4,
            "high": 3,
            "medium": 2,
            "low": 1
        }
        return priority_map.get(priority, 0)

    async def export_analysis_report(self, analysis_results: Dict[str, Any], 
                                   output_path: str = "logs/performance_analysis_report.json") -> str:
        """å¯¼å‡ºåˆ†ææŠ¥å‘Š"""
        import json
        import os
        
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # ç”Ÿæˆä¼˜åŒ–è®¡åˆ’
        optimization_plan = await self.generate_optimization_plan(analysis_results)
        analysis_results["optimization_plan"] = optimization_plan
        
        # å¯¼å‡ºæŠ¥å‘Š
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(analysis_results, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"ğŸ“Š æ€§èƒ½åˆ†ææŠ¥å‘Šå·²å¯¼å‡º: {output_path}")
        return output_path


# å…¨å±€æ€§èƒ½ç“¶é¢ˆåˆ†æå™¨å®ä¾‹
_bottleneck_analyzer = None


def get_bottleneck_analyzer() -> PerformanceBottleneckAnalyzer:
    """è·å–å…¨å±€æ€§èƒ½ç“¶é¢ˆåˆ†æå™¨å®ä¾‹"""
    global _bottleneck_analyzer
    if _bottleneck_analyzer is None:
        _bottleneck_analyzer = PerformanceBottleneckAnalyzer()
    return _bottleneck_analyzer