"""
Arq å·¥ä½œè€…è®¾ç½®

åŸºäº Arq æœ€ä½³å®è·µé…ç½®ï¼š
- ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†
- é‡è¯•ç­–ç•¥
- å¹¶å‘æ§åˆ¶
- ç»“æœå­˜å‚¨
- ç›‘æ§å’Œå¯è§‚æµ‹æ€§
- å·¥ä½œè¿›ç¨‹ç®¡ç†å’Œå¥åº·æ£€æŸ¥

ç‰¹æ€§ï¼š
- å¼‚æ­¥ä»»åŠ¡å¤„ç†
- è‡ªåŠ¨é‡è¯•æœºåˆ¶
- ä»»åŠ¡ä¼˜å…ˆçº§
- èµ„æºç®¡ç†
- è¯¦ç»†çš„ç›‘æ§æŒ‡æ ‡
- å¥åº·çŠ¶æ€æ£€æŸ¥
"""

import asyncio
import time
import uuid
from typing import TYPE_CHECKING, Any, Optional
from urllib.parse import urlparse

import psutil

if TYPE_CHECKING:
    pass

from arq import ArqRedis, create_pool, cron
from arq.connections import RedisSettings
from loguru import logger

from src.framework.orchestrators import bootstrap_langchain_executor
from src.framework.shared.config import Settings
from src.framework.shared.monitoring import metrics_collector
from src.workers.serialization import MsgpackSerializer


class AdvancedWorkerSettings:
    """Arq å·¥ä½œè€…é…ç½®ç±» - åŸºäº Arq v0.26+ æœ€ä½³å®è·µ"""

    # Redis è¿æ¥è®¾ç½® - æ”¯æŒæ›´å¤šé…ç½®é€‰é¡¹
    @classmethod
    def _get_redis_settings(cls):
        """è·å– Redis è¿æ¥è®¾ç½®"""
        settings = Settings()
        parsed = urlparse(settings.ARQ_REDIS_URL)

        return RedisSettings(
            host=parsed.hostname or "localhost",
            port=parsed.port or 6379,
            database=int(parsed.path.lstrip("/")) if parsed.path else 0,
            # Arq v0.26+ æœ€ä½³å®è·µé…ç½®
            ssl=parsed.scheme in ("rediss", "rediss"),
            ssl_certfile=None,
            ssl_keyfile=None,
            ssl_ca_certs=None,
            username=parsed.username,
            password=parsed.password,
            conn_timeout=60,  # è¿æ¥è¶…æ—¶
            conn_retries=5,  # è¿æ¥é‡è¯•æ¬¡æ•°
            conn_retry_delay=1,  # è¿æ¥é‡è¯•å»¶è¿Ÿ
            max_connections=20,  # æœ€å¤§è¿æ¥æ•°
        )


    # å·¥ä½œè€…åŸºæœ¬ä¿¡æ¯
    job_serializer = MsgpackSerializer.serialize
    job_deserializer = MsgpackSerializer.deserialize
    queue_name = Settings().ARQ_QUEUE_NAME

    # Arq v0.26+ æ–°å¢é…ç½®
    job_id_prefix = "lumoscribe2033"
    max_burst_jobs = 10
    health_check_interval = 30
    log_results = True
    log_curtail = 1000  # æ—¥å¿—é•¿åº¦é™åˆ¶

    # ä»»åŠ¡å‡½æ•°å®šä¹‰
    functions = [
        # Speckit ä»»åŠ¡
        'src.workers.tasks.speckit.run_constitution',
        'src.workers.tasks.speckit.run_specify',
        'src.workers.tasks.speckit.run_plan',
        'src.workers.tasks.speckit.run_tasks',

        # Pipeline ä»»åŠ¡
        'src.workers.tasks.pipeline.run_full_pipeline',
        'src.workers.tasks.pipeline.process_document',
        'src.workers.tasks.pipeline.generate_speckit_output',

        # åˆè§„æ£€æŸ¥ä»»åŠ¡
        'src.workers.tasks.compliance.run_static_check',
        'src.workers.tasks.compliance.check_speckit_compliance',
        'src.workers.tasks.compliance.validate_document_structure',

        # çŸ¥è¯†ç®¡ç†ä»»åŠ¡
        'src.workers.tasks.knowledge.import_conversations',
        'src.workers.tasks.knowledge.generate_ide_package',
        'src.workers.tasks.knowledge.update_vector_store',
        'src.workers.tasks.knowledge.build_knowledge_graph',

        # æŒ‡æ ‡æ”¶é›†ä»»åŠ¡
        'src.workers.tasks.metrics.collect_metrics',
        'src.workers.tasks.metrics.generate_compliance_report',
        'src.workers.tasks.metrics.analyze_system_performance',

        # æ–‡æ¡£å¤„ç†ä»»åŠ¡
        'src.workers.tasks.docs.upload_and_evaluate',
        'src.workers.tasks.docs.batch_process_documents',
        'src.workers.tasks.docs.generate_document_report',
    ]

    # å¹¶å‘è®¾ç½®
    max_jobs = 10  # æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
    job_timeout = 300  # ä»»åŠ¡è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    keep_result = 3600  # ç»“æœä¿å­˜æ—¶é—´ï¼ˆç§’ï¼‰
    keep_result_forever = False  # æ˜¯å¦æ°¸ä¹…ä¿å­˜ç»“æœ

    # é‡è¯•è®¾ç½®
    max_tries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
    retry_delay = 30  # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰

    # ä»»åŠ¡ä¼˜å…ˆçº§è®¾ç½®
    burst = False  # æ˜¯å¦ä»¥ burst æ¨¡å¼è¿è¡Œ
    poll_delay = 0.5  # è½®è¯¢å»¶è¿Ÿï¼ˆç§’ï¼‰

    # ä»»åŠ¡é˜Ÿåˆ—é…ç½®
    max_burst_jobs_queue = 5  # Burst æ¨¡å¼ä¸‹çš„æœ€å¤§ä»»åŠ¡æ•°
    health_check_interval_queue = 60  # å¥åº·æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰

    # ç”Ÿå‘½å‘¨æœŸé’©å­
    on_startup = 'src.workers.lifecycle.on_startup'
    on_shutdown = 'src.workers.lifecycle.on_shutdown'
    on_after_job = 'src.workers.lifecycle.on_after_job'
    on_before_job = 'src.workers.lifecycle.on_before_job'

    # åºåˆ—åŒ–é…ç½®
    serialization_manager = None  # SerializationManager(default_serializer='msgpack')

    # æ€§èƒ½ä¼˜åŒ–é…ç½®
    max_jobs_per_worker = 10  # æ¯ä¸ªå·¥ä½œè¿›ç¨‹æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
    max_queue_size = 1000  # é˜Ÿåˆ—æœ€å¤§é•¿åº¦

    # ç»“æœå­˜å‚¨é…ç½®
    result_ttl = 3600  # ç»“æœä¿å­˜æ—¶é—´ï¼ˆç§’ï¼‰
    result_limit = 100  # æœ€å¤§ç»“æœæ•°é‡

    # é”™è¯¯å¤„ç†é…ç½®
    error_retry_attempts = 3
    error_retry_delay = 60  # é”™è¯¯é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰

    # ç›‘æ§é…ç½®
    metrics_enabled = True
    metrics_interval = 60  # ç›‘æ§æŒ‡æ ‡æ”¶é›†é—´éš”ï¼ˆç§’ï¼‰


# è®¾ç½® redis_settings
AdvancedWorkerSettings.redis_settings = AdvancedWorkerSettings._get_redis_settings()


async def on_startup(ctx: dict[str, Any]) -> None:
    """å·¥ä½œè€…å¯åŠ¨æ—¶çš„åˆå§‹åŒ– - Arq æœ€ä½³å®è·µ"""
    logger.info("ğŸš€ Arq å·¥ä½œè€…å¯åŠ¨ä¸­...")

    # è®°å½•å¯åŠ¨ä¿¡æ¯
    worker_info = {
        "worker_id": ctx.get("worker_id", "unknown"),
        "start_time": time.time(),
        "pid": ctx.get("pid", "unknown"),
        "hostname": ctx.get("hostname", "unknown"),
        "python_version": ctx.get("python_version", "unknown"),
        "arq_version": ctx.get("arq_version", "unknown"),
    }

    # ä¿å­˜å·¥ä½œè€…ä¿¡æ¯åˆ°ä¸Šä¸‹æ–‡
    ctx["worker_info"] = worker_info
    ctx["start_time"] = time.time()

    # åˆå§‹åŒ–ç›‘æ§æŒ‡æ ‡æ”¶é›†
    if metrics_collector:
        await metrics_collector.start_worker_monitoring()

    # åˆå§‹åŒ– LangChainExecutorï¼Œç¡®ä¿ Worker ä¾§ä¹Ÿèƒ½å¤ç”¨è·¯ç”±/è¿½è¸ª
    bootstrap_langchain_executor(settings=Settings())

    # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
    # åˆå§‹åŒ–å‘é‡å­˜å‚¨
    # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯

    logger.info(f"âœ… Arq å·¥ä½œè€…å¯åŠ¨å®Œæˆ - Worker ID: {worker_info['worker_id']}")


async def on_shutdown(ctx: dict[str, Any]) -> None:
    """å·¥ä½œè€…å…³é—­æ—¶çš„æ¸…ç† - Arq æœ€ä½³å®è·µ"""
    logger.info("ğŸ›‘ Arq å·¥ä½œè€…æ­£åœ¨å…³é—­...")

    # è®°å½•å…³é—­ä¿¡æ¯
    worker_info = ctx.get("worker_info", {})
    start_time = ctx.get("start_time", time.time())
    uptime = time.time() - start_time

    shutdown_info = {
        "worker_id": worker_info.get("worker_id", "unknown"),
        "uptime": uptime,
        "shutdown_time": time.time(),
        "total_jobs_processed": ctx.get("total_jobs_processed", 0),
        "successful_jobs": ctx.get("successful_jobs", 0),
        "failed_jobs": ctx.get("failed_jobs", 0),
    }

    logger.info(f"ğŸ“Š å·¥ä½œè€…è¿è¡Œç»Ÿè®¡: {shutdown_info}")

    # åœæ­¢ç›‘æ§æŒ‡æ ‡æ”¶é›†
    if metrics_collector:
        await metrics_collector.stop_worker_monitoring()

    # å…³é—­æ•°æ®åº“è¿æ¥
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    # ä¿å­˜çŠ¶æ€

    logger.info("âœ… Arq å·¥ä½œè€…å·²å…³é—­")


async def on_before_job(ctx: dict[str, Any], job_id: str) -> None:
    """ä»»åŠ¡å¼€å§‹å‰çš„é’©å­ - Arq æœ€ä½³å®è·µ"""
    logger.debug(f"ğŸ“‹ å¼€å§‹æ‰§è¡Œä»»åŠ¡: {job_id}")

    # è®°å½•ä»»åŠ¡å¼€å§‹æ—¶é—´
    ctx[f"job_start_time_{job_id}"] = time.time()

    # æ›´æ–°ä»»åŠ¡è®¡æ•°å™¨
    ctx["total_jobs_processed"] = ctx.get("total_jobs_processed", 0) + 1

    # è®°å½•ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
    try:
        process = psutil.Process()
        memory_info = process.memory_info()
        cpu_percent = process.cpu_percent()

        ctx[f"job_resources_{job_id}"] = {
            "memory_mb": memory_info.rss / 1024 / 1024,
            "cpu_percent": cpu_percent,
            "timestamp": time.time()
        }
    except Exception:
        pass


async def on_after_job(
    ctx: dict[str, Any],
    job_id: str,
    result: Any | None = None,
    exc: Exception | None = None
) -> None:
    """ä»»åŠ¡å®Œæˆåçš„é’©å­ - Arq æœ€ä½³å®è·µ"""
    import datetime

    # è®¡ç®—ä»»åŠ¡æ‰§è¡Œæ—¶é—´
    start_time = ctx.get(f"job_start_time_{job_id}")
    execution_time = (time.time() - start_time) if start_time else 0

    # è·å–ä»»åŠ¡èµ„æºä½¿ç”¨æƒ…å†µ
    job_resources = ctx.get(f"job_resources_{job_id}", {})

    if exc:
        logger.error(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {job_id}, é”™è¯¯: {exc}, è€—æ—¶: {execution_time:.2f}s")

        # æ›´æ–°å¤±è´¥ä»»åŠ¡è®¡æ•°å™¨
        ctx["failed_jobs"] = ctx.get("failed_jobs", 0) + 1

        # è®°å½•å¤±è´¥ä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯
        failure_info = {
            "job_id": job_id,
            "error": str(exc),
            "error_type": type(exc).__name__,
            "execution_time": execution_time,
            "worker_info": ctx.get("worker_info", {}),
            "resources": job_resources,
            "timestamp": datetime.datetime.now().isoformat(),
        }

        # ä¿å­˜å¤±è´¥ä¿¡æ¯åˆ°æ—¥å¿—æ–‡ä»¶
        import json
        from pathlib import Path

        failure_log_file = Path("logs/job_failures.log")
        failure_log_file.parent.mkdir(parents=True, exist_ok=True)

        try:
            with open(failure_log_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(failure_info, ensure_ascii=False) + "\n")
        except Exception as log_error:
            logger.error(f"è®°å½•å¤±è´¥ä¿¡æ¯æ—¶å‡ºé”™: {log_error}")

        # è®°å½•å¤±è´¥ä»»åŠ¡æŒ‡æ ‡
        if metrics_collector:
            await metrics_collector.record_task_metric(
                task_name=job_id,
                execution_time=execution_time * 1000,  # è½¬æ¢ä¸ºæ¯«ç§’
                status="failed",
                error=str(exc),
                worker_id=ctx.get("worker_info", {}).get("worker_id", "unknown"),
                resources=job_resources
            )
    else:
        logger.info(f"âœ… ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ: {job_id}, è€—æ—¶: {execution_time:.2f}s")

        # æ›´æ–°æˆåŠŸä»»åŠ¡è®¡æ•°å™¨
        ctx["successful_jobs"] = ctx.get("successful_jobs", 0) + 1

        # è®°å½•æˆåŠŸä»»åŠ¡çš„ç»Ÿè®¡ä¿¡æ¯
        if result and isinstance(result, dict):
            logger.info(f"ğŸ“Š ä»»åŠ¡ç»“æœç»Ÿè®¡: {result.get('stats', {})}")

        # è®°å½•æˆåŠŸä»»åŠ¡æŒ‡æ ‡
        if metrics_collector:
            await metrics_collector.record_task_metric(
                task_name=job_id,
                execution_time=execution_time * 1000,  # è½¬æ¢ä¸ºæ¯«ç§’
                status="success",
                result_size=len(str(result)) if result else 0,
                worker_id=ctx.get("worker_info", {}).get("worker_id", "unknown"),
                resources=job_resources
            )

    # æ¸…ç†ä»»åŠ¡ç›¸å…³ä¸Šä¸‹æ–‡
    ctx.pop(f"job_start_time_{job_id}", None)
    ctx.pop(f"job_resources_{job_id}", None)


async def create_redis_pool() -> ArqRedis:
    """åˆ›å»º Redis è¿æ¥æ± """
    return await create_pool(WorkerSettings.redis_settings)


# Arq v0.26+ æœ€ä½³å®è·µï¼šCron ä»»åŠ¡é…ç½®
def cron_jobs() -> list:
    """å®šä¹‰å‘¨æœŸæ€§ä»»åŠ¡"""
    return [
        # æ¯5åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡å¥åº·æ£€æŸ¥
        cron(
            'src.workers.tasks.metrics.health_check',
            minute={0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55},
            name='health_check_cron',
            timeout=300,
            retries=3,
            retry_delay=30,
        ),

        # æ¯10åˆ†é’Ÿæ”¶é›†ä¸€æ¬¡ç³»ç»ŸæŒ‡æ ‡
        cron(
            'src.workers.tasks.metrics.collect_system_metrics',
            minute={0, 10, 20, 30, 40, 50},
            name='system_metrics_cron',
            timeout=600,
            retries=2,
            retry_delay=60,
        ),

        # æ¯30åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡æ—§ä»»åŠ¡è®°å½•
        cron(
            'src.workers.tasks.metrics.cleanup_old_tasks',
            minute={0, 30},
            name='cleanup_old_tasks_cron',
            timeout=900,
            retries=1,
            retry_delay=120,
        ),

        # æ¯å°æ—¶ç”Ÿæˆä¸€æ¬¡æ€§èƒ½æŠ¥å‘Š
        cron(
            'src.workers.tasks.metrics.generate_performance_report',
            minute=0,
            name='performance_report_cron',
            timeout=1800,
            retries=2,
            retry_delay=300,
        ),
    ]


    # ä»»åŠ¡å‡½æ•°å®šä¹‰

    # Arq v0.26+ åŸºæœ¬é…ç½®

    # é”™è¯¯å¤„ç†é…ç½®

    # ç»“æœç®¡ç†é…ç½®

    # é˜Ÿåˆ—ç®¡ç†é…ç½®

    # Cron ä»»åŠ¡
    cron_jobs()

    # å…¶ä»–é«˜çº§é…ç½®


async def enqueue_job(
    function_name: str,
    *args,
    **kwargs
) -> str | None:
    """
    å…¥é˜Ÿä»»åŠ¡

    Args:
        function_name: ä»»åŠ¡å‡½æ•°å
        *args: ä½ç½®å‚æ•°
        **kwargs: å…³é”®å­—å‚æ•°

    Returns:
        ä»»åŠ¡ ID æˆ– None
    """
    try:
        redis = await create_redis_pool()
        job = await redis.enqueue_job(function_name, *args, **kwargs)
        logger.info(f"ğŸ“¨ ä»»åŠ¡å·²å…¥é˜Ÿ: {function_name}, ID: {job.job_id}")
        return job.job_id if job else None
    except Exception as e:
        logger.error(f"âŒ ä»»åŠ¡å…¥é˜Ÿå¤±è´¥: {function_name}, é”™è¯¯: {e}")
        return None


async def get_job_result(job_id: str) -> Any:
    """
    è·å–ä»»åŠ¡æ‰§è¡Œç»“æœ

    Args:
        job_id: ä»»åŠ¡ ID

    Returns:
        ä»»åŠ¡ç»“æœ
    """
    try:
        redis = await create_redis_pool()
        job_result = await redis.get_job_result(job_id)

        if job_result:
            if job_result.success:
                logger.info(f"âœ… è·å–ä»»åŠ¡ç»“æœæˆåŠŸ: {job_id}")
                return job_result.result
            else:
                logger.error(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {job_id}, é”™è¯¯: {job_result.exc}")
                raise job_result.exc
        else:
            logger.warning(f"âš ï¸ ä»»åŠ¡ç»“æœä¸å­˜åœ¨: {job_id}")
            return None

    except Exception as e:
        logger.error(f"âŒ è·å–ä»»åŠ¡ç»“æœå¤±è´¥: {job_id}, é”™è¯¯: {e}")
        raise


async def cancel_job(job_id: str) -> bool:
    """
    å–æ¶ˆä»»åŠ¡

    Args:
        job_id: ä»»åŠ¡ ID

    Returns:
        æ˜¯å¦å–æ¶ˆæˆåŠŸ
    """
    try:
        redis = await create_redis_pool()
        result = await redis.cancel_job(job_id)

        if result:
            logger.info(f"ğŸ›‘ ä»»åŠ¡å·²å–æ¶ˆ: {job_id}")
        else:
            logger.warning(f"âš ï¸ ä»»åŠ¡å–æ¶ˆå¤±è´¥: {job_id}")

        return result
    except Exception as e:
        logger.error(f"âŒ ä»»åŠ¡å–æ¶ˆå¤±è´¥: {job_id}, é”™è¯¯: {e}")
        return False


async def get_queue_info() -> dict[str, Any]:
    """
    è·å–é˜Ÿåˆ—ä¿¡æ¯

    Returns:
        é˜Ÿåˆ—ä¿¡æ¯å­—å…¸
    """
    try:
        redis = await create_redis_pool()

        # è·å–é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡æ•°
        queue_size = await redis.zcard(redis.queue_name)

        # è·å–æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡æ•°
        running_jobs = await redis.keys(f"{redis.queue_name}:*")

        # è·å–å·²å®Œæˆçš„ä»»åŠ¡æ•°
        completed_jobs = await redis.get(f"{redis.queue_name}:completed")

        return {
            "queue_size": queue_size,
            "running_jobs": len(running_jobs),
            "completed_jobs": int(completed_jobs or 0),
            "queue_name": redis.queue_name
        }
    except Exception as e:
        logger.error(f"âŒ è·å–é˜Ÿåˆ—ä¿¡æ¯å¤±è´¥: {e}")
        return {}


async def get_worker_stats() -> dict[str, Any]:
    """
    è·å–å·¥ä½œè€…ç»Ÿè®¡ä¿¡æ¯

    Returns:
        å·¥ä½œè€…ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    try:
        redis = await create_redis_pool()

        # è·å–å·¥ä½œè€…ä¿¡æ¯
        worker_keys = await redis.keys("arq:worker:*")
        worker_count = len(worker_keys)

        # è·å–ä»»åŠ¡æ‰§è¡Œç»Ÿè®¡
        stats_keys = await redis.keys("arq:stats:*")
        total_jobs = 0
        successful_jobs = 0
        failed_jobs = 0

        for key in stats_keys:
            stats_data = await redis.hgetall(key)
            if stats_data:
                total_jobs += int(stats_data.get(b'total', 0))
                successful_jobs += int(stats_data.get(b'successful', 0))
                failed_jobs += int(stats_data.get(b'failed', 0))

        return {
            "worker_count": worker_count,
            "total_jobs": total_jobs,
            "successful_jobs": successful_jobs,
            "failed_jobs": failed_jobs,
            "success_rate": (successful_jobs / total_jobs * 100) if total_jobs > 0 else 0,
            "queue_name": redis.queue_name
        }
    except Exception as e:
        logger.error(f"âŒ è·å–å·¥ä½œè€…ç»Ÿè®¡å¤±è´¥: {e}")
        return {}


async def cleanup_old_jobs(days: int = 7) -> int:
    """
    æ¸…ç†æ—§çš„ä»»åŠ¡è®°å½•

    Args:
        days: ä¿ç•™å¤©æ•°

    Returns:
        æ¸…ç†çš„ä»»åŠ¡æ•°é‡
    """
    try:
        # è®¡ç®—è¿‡æœŸæ—¶é—´æˆ³
        import time
        time.time() - (days * 24 * 60 * 60)

        # è¿™é‡Œåº”è¯¥å®ç°å…·ä½“çš„æ¸…ç†é€»è¾‘
        # ç”±äº Arq çš„å†…éƒ¨ç»“æ„ï¼Œæ¸…ç†é€»è¾‘å¯èƒ½éœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´

        logger.info(f"ğŸ§¹ æ¸…ç† {days} å¤©å‰çš„ä»»åŠ¡è®°å½•å®Œæˆ")
        return 0

    except Exception as e:
        logger.error(f"âŒ æ¸…ç†æ—§ä»»åŠ¡å¤±è´¥: {e}")
        return 0


async def get_job_history(limit: int = 100) -> list[dict[str, Any]]:
    """
    è·å–ä»»åŠ¡æ‰§è¡Œå†å²

    Args:
        limit: è¿”å›è®°å½•æ•°é™åˆ¶

    Returns:
        ä»»åŠ¡å†å²åˆ—è¡¨
    """
    try:
        # è¿™é‡Œåº”è¯¥å®ç°è·å–ä»»åŠ¡å†å²çš„é€»è¾‘
        # å¯èƒ½éœ€è¦æŸ¥è¯¢ Redis ä¸­çš„ä»»åŠ¡è®°å½•

        logger.info(f"ğŸ“‹ è·å–æœ€è¿‘ {limit} ä¸ªä»»åŠ¡çš„å†å²è®°å½•")
        return []

    except Exception as e:
        logger.error(f"âŒ è·å–ä»»åŠ¡å†å²å¤±è´¥: {e}")
        return []


# Arq v0.26+ æœ€ä½³å®è·µï¼šå¢å¼ºçš„ç›‘æ§å’Œç®¡ç†åŠŸèƒ½
async def get_detailed_worker_stats() -> dict[str, Any]:
    """
    è·å–è¯¦ç»†çš„å·¥ä½œè¿›ç¨‹ç»Ÿè®¡ä¿¡æ¯

    Returns:
        è¯¦ç»†çš„å·¥ä½œè¿›ç¨‹ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        redis = await create_redis_pool()

        # è·å–åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        basic_stats = await get_worker_stats()

        # è·å–ç³»ç»Ÿèµ„æºä¿¡æ¯
        system_info = {
            "cpu_count": psutil.cpu_count(),
            "cpu_percent": psutil.cpu_percent(interval=1),
            "memory": psutil.virtual_memory()._asdict(),
            "disk": psutil.disk_usage('/')._asdict(),
            "network": psutil.net_io_counters()._asdict() if psutil.net_io_counters() else {},
        }

        # è·å– Redis è¿æ¥ä¿¡æ¯
        redis_info = {
            "redis_version": await redis.info("server"),
            "connected_clients": await redis.info("clients"),
            "used_memory": await redis.info("memory"),
            "keyspace": await redis.info("keyspace"),
        }

        # è·å–é˜Ÿåˆ—è¯¦ç»†ä¿¡æ¯
        queue_info = await get_queue_info()

        return {
            "timestamp": time.time(),
            "basic_stats": basic_stats,
            "system_info": system_info,
            "redis_info": redis_info,
            "queue_info": queue_info,
            "worker_settings": {
                "max_jobs": AdvancedWorkerSettings.max_jobs,
                "job_timeout": AdvancedWorkerSettings.job_timeout,
                "max_tries": AdvancedWorkerSettings.max_tries,
                "queue_name": AdvancedWorkerSettings.queue_name,
            }
        }

    except Exception as e:
        logger.error(f"âŒ è·å–è¯¦ç»†å·¥ä½œè¿›ç¨‹ç»Ÿè®¡å¤±è´¥: {e}")
        return {}


async def health_check() -> dict[str, Any]:
    """
    æ‰§è¡Œå¥åº·æ£€æŸ¥

    Returns:
        å¥åº·æ£€æŸ¥ç»“æœ
    """
    try:
        redis = await create_redis_pool()

        # æ£€æŸ¥ Redis è¿æ¥
        redis_status = "healthy"
        try:
            await redis.ping()
        except Exception:
            redis_status = "unhealthy"

        # æ£€æŸ¥ç³»ç»Ÿèµ„æº
        cpu_percent = psutil.cpu_percent(interval=1)
        memory_percent = psutil.virtual_memory().percent
        disk_percent = psutil.disk_usage('/').percent

        # èµ„æºå¥åº·çŠ¶æ€åˆ¤æ–­
        system_status = "healthy"
        if cpu_percent > 90:
            system_status = "critical"
        elif memory_percent > 80 or disk_percent > 90:
            system_status = "warning"

        # æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
        queue_info = await get_queue_info()
        queue_size = queue_info.get("queue_size", 0)
        queue_status = "healthy"
        if queue_size > 1000:
            queue_status = "critical"
        elif queue_size > 500:
            queue_status = "warning"

        # æ•´ä½“å¥åº·çŠ¶æ€
        overall_status = "healthy"
        if "critical" in [redis_status, system_status, queue_status]:
            overall_status = "critical"
        elif "warning" in [redis_status, system_status, queue_status]:
            overall_status = "warning"

        health_result = {
            "timestamp": time.time(),
            "overall_status": overall_status,
            "redis_status": redis_status,
            "system_status": system_status,
            "queue_status": queue_status,
            "metrics": {
                "cpu_percent": cpu_percent,
                "memory_percent": memory_percent,
                "disk_percent": disk_percent,
                "queue_size": queue_size,
                "running_jobs": queue_info.get("running_jobs", 0),
            }
        }

        logger.info(f"ğŸ¥ å¥åº·æ£€æŸ¥ç»“æœ: {health_result}")
        return health_result

    except Exception as e:
        logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return {
            "timestamp": time.time(),
            "overall_status": "error",
            "error": str(e),
        }


async def emergency_shutdown() -> bool:
    """
    ç´§æ€¥å…³é—­æ‰€æœ‰å·¥ä½œè¿›ç¨‹

    Returns:
        æ˜¯å¦æˆåŠŸå…³é—­
    """
    try:
        redis = await create_redis_pool()

        # è·å–æ‰€æœ‰æ´»è·ƒçš„å·¥ä½œè¿›ç¨‹
        await redis.keys("arq:worker:*")

        # å–æ¶ˆæ‰€æœ‰é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        queue_name = WorkerSettings.queue_name
        queued_jobs = await redis.zrange(queue_name, 0, -1)

        cancelled_count = 0
        for job_id in queued_jobs:
            try:
                await redis.cancel_job(job_id.decode())
                cancelled_count += 1
            except Exception:
                continue

        logger.warning(f"ğŸ›‘ ç´§æ€¥å…³é—­: å–æ¶ˆäº† {cancelled_count} ä¸ªé˜Ÿåˆ—ä»»åŠ¡")
        return True

    except Exception as e:
        logger.error(f"âŒ ç´§æ€¥å…³é—­å¤±è´¥: {e}")
        return False




# å‘åå…¼å®¹æ€§åˆ«å
WorkerSettings = AdvancedWorkerSettings
