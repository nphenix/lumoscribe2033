#!/usr/bin/env python3
# generated: python -m src.cli metadata-injector @ 2025-11-19T13:04:42Z
# classification: developer
"""
å¢å¼ºç‰ˆ RAG å’Œå­˜å‚¨é€‚é…æ¼”ç¤ºè„šæœ¬

å±•ç¤ºåŸºäº LlamaIndex æœ€ä½³å®è·µçš„å¢å¼ºç‰ˆç»„ä»¶åŠŸèƒ½ï¼š
- EnhancedVectorStoreManagerï¼šLlamaIndex Chroma é›†æˆ
- EnhancedGraphStoreManagerï¼šå¤šåç«¯å›¾å­˜å‚¨æ”¯æŒ
- EnhancedIndexServiceï¼šAutoRetriever æ™ºèƒ½æ£€ç´¢
- æ€§èƒ½ç›‘æ§å’ŒæŒ‡æ ‡æ”¶é›†
"""

import os
import time
import logging
from typing import List, Dict, Any

from llama_index.core.schema import Document as LlamaDocument

from src.framework.shared.logging import get_logger
from src.framework.storage.enhanced_vector_store import EnhancedVectorStoreManager
from src.framework.storage.enhanced_graph_store import EnhancedGraphStoreManager
from src.framework.rag.enhanced_index_service import EnhancedIndexService
from src.framework.shared.models import DocumentChunk

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = get_logger(__name__)


def create_sample_documents() -> List[LlamaDocument]:
    """åˆ›å»ºç¤ºä¾‹æ–‡æ¡£"""
    documents = [
        LlamaDocument(
            text="Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œç”± Guido van Rossum äº 1991 å¹´åˆ›å»ºã€‚"
                 "Python ä»¥å…¶ç®€æ´æ˜“è¯»çš„è¯­æ³•è€Œé—»åï¼Œæ”¯æŒå¤šç§ç¼–ç¨‹èŒƒå¼ï¼ŒåŒ…æ‹¬é¢å‘å¯¹è±¡ã€"
                 "å‡½æ•°å¼å’Œè¿‡ç¨‹å¼ç¼–ç¨‹ã€‚Python æ‹¥æœ‰åºå¤§çš„æ ‡å‡†åº“å’Œæ´»è·ƒçš„ç¤¾åŒºã€‚",
            metadata={"source": "python_intro", "category": "programming", "author": "Guido"}
        ),
        LlamaDocument(
            text="æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä¸“æ³¨äºå¼€å‘ç®—æ³•å’Œç»Ÿè®¡æ¨¡å‹ï¼Œ"
                 "ä½¿è®¡ç®—æœºç³»ç»Ÿèƒ½å¤Ÿæ‰§è¡Œç‰¹å®šä»»åŠ¡è€Œæ— éœ€ä½¿ç”¨æ˜ç¡®çš„æŒ‡ä»¤ã€‚"
                 "æœºå™¨å­¦ä¹ ç®—æ³•åŸºäºæ ·æœ¬æ•°æ®æ„å»ºé¢„æµ‹æˆ–å†³ç­–æ¨¡å‹ã€‚",
            metadata={"source": "ml_intro", "category": "ai", "author": "ML Expert"}
        ),
        LlamaDocument(
            text="æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œä½¿ç”¨åŒ…å«å¤šä¸ªéšè—å±‚çš„ç¥ç»ç½‘ç»œã€‚"
                 "æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œè¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚",
            metadata={"source": "deep_learning", "category": "ai", "author": "DL Researcher"}
        ),
        LlamaDocument(
            text="ChromaDB æ˜¯ä¸€ä¸ªå¼€æºçš„å‘é‡æ•°æ®åº“ï¼Œä¸“ä¸º AI åº”ç”¨ç¨‹åºè®¾è®¡ã€‚"
                 "å®ƒæä¾›ç®€å•çš„ API æ¥å­˜å‚¨å’ŒæŸ¥è¯¢åµŒå…¥å‘é‡ï¼Œæ”¯æŒæŒä¹…åŒ–ã€è¿‡æ»¤å’Œæ··åˆæœç´¢ã€‚",
            metadata={"source": "chromadb", "category": "database", "author": "Chroma Team"}
        ),
        LlamaDocument(
            text="LlamaIndex æ˜¯ä¸€ä¸ªæ•°æ®æ¡†æ¶ï¼Œç”¨äºæ„å»º LLM åº”ç”¨ç¨‹åºã€‚"
                 "å®ƒæä¾›äº†è¿æ¥ã€ç´¢å¼•å’Œè®¿é—®ç§æœ‰æˆ–ç‰¹å®šé¢†åŸŸæ•°æ®çš„å·¥å…·å’ŒæŠ½è±¡ã€‚"
                 "LlamaIndex æ”¯æŒå¤šç§æ•°æ®æºå’Œå‘é‡å­˜å‚¨ã€‚",
            metadata={"source": "llamaindex", "category": "framework", "author": "LlamaIndex Team"}
        ),
        LlamaDocument(
            text="å‘é‡åµŒå…¥æ˜¯å°†æ–‡æœ¬ã€å›¾åƒæˆ–å…¶ä»–æ•°æ®è½¬æ¢ä¸ºæ•°å€¼å‘é‡çš„è¿‡ç¨‹ã€‚"
                 "è¿™äº›å‘é‡æ•è·æ•°æ®çš„è¯­ä¹‰ç‰¹å¾ï¼Œä½¿å¾—ç›¸ä¼¼çš„å†…å®¹åœ¨å‘é‡ç©ºé—´ä¸­è·ç¦»æ›´è¿‘ã€‚"
                 "åµŒå…¥å¹¿æ³›ç”¨äºæœç´¢ã€æ¨èå’Œèšç±»ä»»åŠ¡ã€‚",
            metadata={"source": "embeddings", "category": "ml_concept", "author": "ML Professor"}
        ),
        LlamaDocument(
            text="å›¾æ•°æ®åº“ä½¿ç”¨å›¾ç»“æ„å­˜å‚¨æ•°æ®ï¼Œå…¶ä¸­èŠ‚ç‚¹è¡¨ç¤ºå®ä½“ï¼Œ"
                 "è¾¹è¡¨ç¤ºå®ä½“ä¹‹é—´çš„å…³ç³»ã€‚Neo4j æ˜¯æœ€æµè¡Œçš„å›¾æ•°æ®åº“ä¹‹ä¸€ï¼Œ"
                 "é€‚ç”¨äºç¤¾äº¤ç½‘ç»œåˆ†æã€æ¨èç³»ç»Ÿå’Œæ¬ºè¯ˆæ£€æµ‹ã€‚",
            metadata={"source": "graph_db", "category": "database", "author": "Graph Expert"}
        ),
        LlamaDocument(
            text="è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé¢†åŸŸï¼Œ"
                 "ä¸“æ³¨äºè®¡ç®—æœºä¸äººç±»è¯­è¨€ä¹‹é—´çš„äº¤äº’ã€‚"
                 "NLP æŠ€æœ¯åŒ…æ‹¬æ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æã€æœºå™¨ç¿»è¯‘å’Œé—®ç­”ç³»ç»Ÿã€‚",
            metadata={"source": "nlp", "category": "ai", "author": "NLP Specialist"}
        ),
        LlamaDocument(
            text="RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ˜¯ä¸€ç§ AI æ¶æ„ï¼Œ"
                 "ç»“åˆäº†ä¿¡æ¯æ£€ç´¢å’Œæ–‡æœ¬ç”Ÿæˆã€‚RAG ç³»ç»Ÿé¦–å…ˆæ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼Œ"
                 "ç„¶åä½¿ç”¨è¿™äº›æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡æ¥ç”Ÿæˆæ›´å‡†ç¡®å’Œç›¸å…³çš„å“åº”ã€‚",
            metadata={"source": "rag", "category": "ai", "author": "RAG Researcher"}
        ),
        LlamaDocument(
            text="çŸ¥è¯†å›¾è°±æ˜¯ç»“æ„åŒ–çŸ¥è¯†çš„å›¾å½¢è¡¨ç¤ºï¼Œ"
                 "å…¶ä¸­èŠ‚ç‚¹è¡¨ç¤ºæ¦‚å¿µæˆ–å®ä½“ï¼Œè¾¹è¡¨ç¤ºå®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚"
                 "çŸ¥è¯†å›¾è°±å¹¿æ³›ç”¨äºæœç´¢å¼•æ“ã€æ¨èç³»ç»Ÿå’Œè¯­ä¹‰æœç´¢ã€‚",
            metadata={"source": "knowledge_graph", "category": "ai", "author": "Knowledge Engineer"}
        )
    ]
    return documents


def demonstrate_enhanced_vector_store():
    """æ¼”ç¤ºå¢å¼ºç‰ˆå‘é‡å­˜å‚¨ç®¡ç†å™¨"""
    print("\n" + "="*60)
    print("ğŸ” æ¼”ç¤ºå¢å¼ºç‰ˆå‘é‡å­˜å‚¨ç®¡ç†å™¨")
    print("="*60)
    
    try:
        # åˆå§‹åŒ–å¢å¼ºç‰ˆå‘é‡å­˜å‚¨ç®¡ç†å™¨
        vector_manager = EnhancedVectorStoreManager(persist_dir="./vector/enhanced_chroma")
        
        # åˆ›å»ºç¤ºä¾‹æ–‡æ¡£
        documents = create_sample_documents()
        print(f"âœ… åˆ›å»ºäº† {len(documents)} ä¸ªç¤ºä¾‹æ–‡æ¡£")
        
        # åˆ›å»ºç´¢å¼•
        print("ğŸš€ åˆ›å»ºå‘é‡ç´¢å¼•...")
        index = vector_manager.create_index(documents, collection_name="demo_docs")
        print("âœ… ç´¢å¼•åˆ›å»ºæˆåŠŸ")
        
        # è·å–é›†åˆä¿¡æ¯
        collection_info = vector_manager.get_collection_info("demo_docs")
        print(f"ğŸ“Š é›†åˆä¿¡æ¯: {collection_info}")
        
        # åˆ›å»ºæŸ¥è¯¢å¼•æ“
        print("ğŸ¯ åˆ›å»ºæŸ¥è¯¢å¼•æ“...")
        query_engine = vector_manager.create_query_engine("demo_docs", similarity_top_k=3)
        
        # æ‰§è¡ŒæŸ¥è¯¢
        test_queries = [
            "ä»€ä¹ˆæ˜¯ Python ç¼–ç¨‹è¯­è¨€ï¼Ÿ",
            "æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
            "å‘é‡æ•°æ®åº“æœ‰å“ªäº›ï¼Ÿ",
            "ä»€ä¹ˆæ˜¯ RAG æ¶æ„ï¼Ÿ"
        ]
        
        for query in test_queries:
            print(f"\nâ“ æŸ¥è¯¢: {query}")
            start_time = time.time()
            response = query_engine.query(query)
            query_time = time.time() - start_time
            print(f"â±ï¸  æŸ¥è¯¢è€—æ—¶: {query_time:.3f}s")
            print(f"ğŸ“„ å“åº”: {str(response)[:200]}...")
        
        # æ¼”ç¤ºé«˜çº§åŠŸèƒ½
        print("\nğŸ”§ æ¼”ç¤ºé«˜çº§åŠŸèƒ½...")
        
        # æ·»åŠ æ–°æ–‡æ¡£
        new_doc = LlamaDocument(
            text="AutoRetriever æ˜¯ LlamaIndex çš„æ™ºèƒ½æ£€ç´¢å™¨ï¼Œ"
                 "èƒ½å¤Ÿè‡ªåŠ¨é€‰æ‹©æœ€ä½³çš„æ£€ç´¢ç­–ç•¥ã€‚",
            metadata={"source": "autoretriever", "category": "llamaindex"}
        )
        
        vector_manager.add_documents_to_index([new_doc], "demo_docs")
        print("âœ… æ·»åŠ æ–°æ–‡æ¡£åˆ°ç´¢å¼•")
        
        # æ£€ç´¢æ–°æ–‡æ¡£
        results = vector_manager.get_index("demo_docs").as_retriever(similarity_top_k=2).retrieve("AutoRetriever")
        print(f"âœ… æ£€ç´¢åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¢å¼ºç‰ˆå‘é‡å­˜å‚¨æ¼”ç¤ºå¤±è´¥: {e}")
        return False


def demonstrate_enhanced_graph_store():
    """æ¼”ç¤ºå¢å¼ºç‰ˆå›¾å­˜å‚¨ç®¡ç†å™¨"""
    print("\n" + "="*60)
    print("ğŸ•¸ï¸ æ¼”ç¤ºå¢å¼ºç‰ˆå›¾å­˜å‚¨ç®¡ç†å™¨")
    print("="*60)
    
    try:
        # åˆå§‹åŒ– NetworkX åç«¯
        graph_manager = EnhancedGraphStoreManager(
            backend_type="networkx",
            db_path="./graph/enhanced_graph.gexf"
        )
        
        print("âœ… NetworkX å›¾å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # è·å–å›¾ç»Ÿè®¡ä¿¡æ¯
        stats = graph_manager.get_graph_stats("default")
        print(f"ğŸ“Š å›¾ç»Ÿè®¡ä¿¡æ¯: {stats}")
        
        # æ¼”ç¤ºå›¾å¯è§†åŒ–ï¼ˆå¦‚æœå¯èƒ½ï¼‰
        try:
            viz_file = graph_manager.visualize_graph(
                backend_name="default",
                output_file="enhanced_graph_visualization.html"
            )
            if viz_file:
                print(f"âœ… å›¾å¯è§†åŒ–æ–‡ä»¶å·²ç”Ÿæˆ: {viz_file}")
        except Exception as e:
            print(f"âš ï¸  å›¾å¯è§†åŒ–å¤±è´¥: {e}")
        
        # æ¼”ç¤ºå¤šåç«¯æ”¯æŒ
        print("\nğŸ”„ æ¼”ç¤ºå¤šåç«¯æ”¯æŒ...")
        backends = graph_manager.list_backends()
        print(f"å¯ç”¨åç«¯: {backends}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¢å¼ºç‰ˆå›¾å­˜å‚¨æ¼”ç¤ºå¤±è´¥: {e}")
        return False


def demonstrate_enhanced_index_service():
    """æ¼”ç¤ºå¢å¼ºç‰ˆç´¢å¼•æœåŠ¡"""
    print("\n" + "="*60)
    print("âš¡ æ¼”ç¤ºå¢å¼ºç‰ˆç´¢å¼•æœåŠ¡")
    print("="*60)
    
    try:
        # åˆå§‹åŒ–å¢å¼ºç‰ˆç´¢å¼•æœåŠ¡
        enhanced_service = EnhancedIndexService(
            enable_auto_retriever=True,
            enable_query_analysis=True,
            enable_metrics=True
        )
        
        print("âœ… å¢å¼ºç‰ˆç´¢å¼•æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        
        # åˆ›å»ºç¤ºä¾‹æ–‡æ¡£
        documents = create_sample_documents()
        
        # åˆ†ææŸ¥è¯¢
        test_queries = [
            "Python ç¼–ç¨‹è¯­è¨€çš„ç‰¹ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ",
            "æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„åŒºåˆ«",
            "å‘é‡æ•°æ®åº“å’Œå›¾æ•°æ®åº“çš„æ¯”è¾ƒ",
            "RAG ç³»ç»Ÿå¦‚ä½•å·¥ä½œï¼Ÿ"
        ]
        
        print("\nğŸ” æŸ¥è¯¢åˆ†ææ¼”ç¤º...")
        for query in test_queries:
            analysis = enhanced_service.analyze_query(query)
            print(f"â“ æŸ¥è¯¢: {query[:30]}...")
            print(f"   æ„å›¾: {analysis.intent}")
            print(f"   å¤æ‚åº¦: {analysis.complexity}")
            print(f"   å»ºè®®ç­–ç•¥: {analysis.suggested_strategies}")
        
        # æ£€ç´¢æ¼”ç¤º
        print("\nğŸ¯ æ£€ç´¢åŠŸèƒ½æ¼”ç¤º...")
        
        for query in test_queries[:2]:
            print(f"\nâ“ æ‰§è¡Œæ£€ç´¢: {query[:30]}...")
            
            # æµ‹è¯•ä¸åŒç­–ç•¥
            strategies = ["auto", "vector", "keyword"]
            
            for strategy in strategies:
                start_time = time.time()
                try:
                    results = enhanced_service.retrieve(
                        query, 
                        collection_name="demo_docs",
                        strategy=strategy,
                        top_k=3
                    )
                    retrieval_time = time.time() - start_time
                    print(f"   ç­–ç•¥ {strategy}: {len(results)} ç»“æœ, è€—æ—¶: {retrieval_time:.3f}s")
                except Exception as e:
                    print(f"   ç­–ç•¥ {strategy}: å¤±è´¥ - {e}")
        
        # æ€§èƒ½æŒ‡æ ‡
        print("\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡...")
        metrics = enhanced_service.get_retrieval_metrics()
        print(f"ğŸ“Š æ£€ç´¢æŒ‡æ ‡: {metrics}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¢å¼ºç‰ˆç´¢å¼•æœåŠ¡æ¼”ç¤ºå¤±è´¥: {e}")
        return False


def demonstrate_integration():
    """æ¼”ç¤ºç»„ä»¶é›†æˆ"""
    print("\n" + "="*60)
    print("ğŸ”— æ¼”ç¤ºç»„ä»¶é›†æˆ")
    print("="*60)
    
    try:
        # åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
        vector_manager = EnhancedVectorStoreManager(persist_dir="./vector/integration_chroma")
        graph_manager = EnhancedGraphStoreManager(backend_type="networkx")
        enhanced_service = EnhancedIndexService(
            vector_store_manager=vector_manager,
            graph_store_manager=graph_manager
        )
        
        print("âœ… æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
        
        # åˆ›å»ºé›†æˆæµ‹è¯•æ–‡æ¡£
        documents = create_sample_documents()
        
        # ä½¿ç”¨é›†æˆæœåŠ¡åˆ›å»ºç´¢å¼•
        print("ğŸš€ åˆ›å»ºé›†æˆç´¢å¼•...")
        index = vector_manager.create_index(documents, "integration_test")
        print("âœ… é›†æˆç´¢å¼•åˆ›å»ºæˆåŠŸ")
        
        # æ‰§è¡Œé›†æˆæ£€ç´¢
        test_query = "Python å’Œæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ"
        print(f"ğŸ” æ‰§è¡Œé›†æˆæ£€ç´¢: {test_query}")
        
        results = enhanced_service.retrieve(
            test_query,
            collection_name="integration_test",
            strategy="auto",
            top_k=5
        )
        
        print(f"âœ… æ£€ç´¢åˆ° {len(results)} ä¸ªç»“æœ")
        
        # æ˜¾ç¤ºç»“æœ
        for i, result in enumerate(results[:3]):
            print(f"   ç»“æœ {i+1}: {result.node.text[:100]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç»„ä»¶é›†æˆæ¼”ç¤ºå¤±è´¥: {e}")
        return False


def run_performance_benchmark():
    """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("\n" + "="*60)
    print("ğŸƒ æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("="*60)
    
    try:
        # åˆå§‹åŒ–ç»„ä»¶
        vector_manager = EnhancedVectorStoreManager(persist_dir="./vector/benchmark_chroma")
        enhanced_service = EnhancedIndexService()
        
        # åˆ›å»ºå¤§é‡æµ‹è¯•æ–‡æ¡£
        large_document_count = 100
        print(f"ğŸ“ åˆ›å»º {large_document_count} ä¸ªæµ‹è¯•æ–‡æ¡£...")
        
        documents = []
        for i in range(large_document_count):
            doc = LlamaDocument(
                text=f"è¿™æ˜¯æµ‹è¯•æ–‡æ¡£ {i} çš„å†…å®¹ã€‚æ–‡æ¡£åŒ…å«ä¸€äº›å…³é”®è¯å¦‚ Pythonã€æœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½ç­‰ã€‚"
                     f"æ–‡æ¡£ç¼–å· {i} å¸®åŠ©æµ‹è¯•ç³»ç»Ÿçš„æ€§èƒ½å’Œå¯æ‰©å±•æ€§ã€‚",
                metadata={"doc_id": i, "category": f"category_{i % 5}"}
            )
            documents.append(doc)
        
        # æµ‹è¯•ç´¢å¼•åˆ›å»ºæ€§èƒ½
        print("ğŸš€ æµ‹è¯•ç´¢å¼•åˆ›å»ºæ€§èƒ½...")
        start_time = time.time()
        index = vector_manager.create_index(documents, "benchmark_docs")
        index_time = time.time() - start_time
        print(f"âœ… ç´¢å¼•åˆ›å»ºè€—æ—¶: {index_time:.3f}s")
        
        # æµ‹è¯•æ£€ç´¢æ€§èƒ½
        print("ğŸ¯ æµ‹è¯•æ£€ç´¢æ€§èƒ½...")
        test_queries = ["Python", "æœºå™¨å­¦ä¹ ", "äººå·¥æ™ºèƒ½", "æ–‡æ¡£", "æµ‹è¯•"]
        
        retrieval_times = []
        for query in test_queries:
            start_time = time.time()
            results = enhanced_service.retrieve(
                query,
                collection_name="benchmark_docs",
                strategy="auto",
                top_k=10
            )
            retrieval_time = time.time() - start_time
            retrieval_times.append(retrieval_time)
            print(f"   æŸ¥è¯¢ '{query}': {len(results)} ç»“æœ, è€—æ—¶: {retrieval_time:.3f}s")
        
        avg_retrieval_time = sum(retrieval_times) / len(retrieval_times)
        print(f"ğŸ“Š å¹³å‡æ£€ç´¢è€—æ—¶: {avg_retrieval_time:.3f}s")
        
        # æµ‹è¯•ç¼“å­˜æ•ˆæœ
        print("ğŸ’¾ æµ‹è¯•ç¼“å­˜æ•ˆæœ...")
        cache_test_query = "Python"
        
        # ç¬¬ä¸€æ¬¡æŸ¥è¯¢ï¼ˆæ— ç¼“å­˜ï¼‰
        start_time = time.time()
        results1 = enhanced_service.retrieve(
            cache_test_query,
            collection_name="benchmark_docs",
            strategy="auto",
            top_k=5
        )
        first_query_time = time.time() - start_time
        
        # ç¬¬äºŒæ¬¡æŸ¥è¯¢ï¼ˆæœ‰ç¼“å­˜ï¼‰
        start_time = time.time()
        results2 = enhanced_service.retrieve(
            cache_test_query,
            collection_name="benchmark_docs",
            strategy="auto",
            top_k=5
        )
        second_query_time = time.time() - start_time
        
        print(f"   é¦–æ¬¡æŸ¥è¯¢è€—æ—¶: {first_query_time:.3f}s")
        print(f"   ç¼“å­˜æŸ¥è¯¢è€—æ—¶: {second_query_time:.3f}s")
        print(f"   ç¼“å­˜åŠ é€Ÿæ¯”: {first_query_time/second_query_time:.2f}x")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å¢å¼ºç‰ˆ RAG å’Œå­˜å‚¨é€‚é…æ¼”ç¤º")
    print("="*60)
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs("./vector", exist_ok=True)
    os.makedirs("./graph", exist_ok=True)
    
    # è¿è¡Œæ¼”ç¤º
    results = []
    
    results.append(demonstrate_enhanced_vector_store())
    results.append(demonstrate_enhanced_graph_store())
    results.append(demonstrate_enhanced_index_service())
    results.append(demonstrate_integration())
    results.append(run_performance_benchmark())
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“‹ æ¼”ç¤ºæ€»ç»“")
    print("="*60)
    
    demo_names = [
        "å¢å¼ºç‰ˆå‘é‡å­˜å‚¨ç®¡ç†å™¨",
        "å¢å¼ºç‰ˆå›¾å­˜å‚¨ç®¡ç†å™¨", 
        "å¢å¼ºç‰ˆç´¢å¼•æœåŠ¡",
        "ç»„ä»¶é›†æˆ",
        "æ€§èƒ½åŸºå‡†æµ‹è¯•"
    ]
    
    for i, (name, success) in enumerate(zip(demo_names, results)):
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        print(f"{i+1}. {name}: {status}")
    
    total_success = sum(results)
    total_demos = len(results)
    
    print(f"\nğŸ“Š æ€»ä½“æˆåŠŸç‡: {total_success}/{total_demos} ({total_success/total_demos*100:.1f}%)")
    
    if total_success == total_demos:
        print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºéƒ½æˆåŠŸå®Œæˆï¼")
    else:
        print("âš ï¸  éƒ¨åˆ†æ¼”ç¤ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
    
    print("\nğŸ’¡ æç¤º:")
    print("- å¢å¼ºç‰ˆç»„ä»¶åŸºäº LlamaIndex æœ€ä½³å®è·µæ„å»º")
    print("- æä¾›äº†æ›´å¥½çš„æ€§èƒ½ã€å¯æ‰©å±•æ€§å’Œæ˜“ç”¨æ€§")
    print("- æ”¯æŒå‘åå…¼å®¹ï¼Œå¯ä»¥é€æ­¥è¿ç§»ç°æœ‰ä»£ç ")
    print("- åŒ…å«å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ€§èƒ½ç›‘æ§")


if __name__ == "__main__":
    main()